{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjunte una Jupyter Notebook en donde:\n",
    "1. quede expresado el desarrollo matemático que permite obtener el valor del nivel de decisión para el caso del ejemplo planteado en la clase, pero esta vez para una regla de decisión MAP con valores de intensidad de   $\\lambda_0= 1$  y $\\lambda_1=3$ y con probabilidades de hipótesis  $P_H(0)=0.7$  y  $P_H(1)=0.3 .$\n",
    "2. Genere una simulación Monte Carlo del problema para obtener la probabilidad de error cuando se utiliza el nivel de decisión obtenido en el punto anterior.\n",
    "3. Cambie el nivel de decisión por el valor obtenido para el caso ML (modifique solo ese valor) y compare el resultado con el valor de probabilidad de error obtenido en el punto anterior. Saque conclusiones de la observación.\n",
    "  \n",
    "RESPUESTA: nivel de decisión = 2.5917 ; Probabilidad de error aprox. 0.183\n",
    "\n",
    "Ayuda: El siguiente código genera hipótesis binarias con distintas probabilidades:\n",
    "z = np.random.uniform(size=nb_samples)\n",
    "ref = 0.7\n",
    "hypothesis = [1 if z[i]>=ref else 0 for i in range(len(z))]\n",
    "\n",
    "(Para una mayor comprensión de este código, analícelo con histogramas antes de utilizarlo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respuestas\n",
    "---\n",
    "1. Usando la regla de decisión MAP, $\\hat{H}(y) = arg \\underset{i \\in H}{MAX}  P_{Y|H}(y|i)$ \n",
    "\n",
    "    $P_{Y|H}(y|1)*P_H(1)  \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}} P_{Y|H}(y|0)*P_H(0)$\n",
    "\n",
    "    Ahora, reemplanzando $P_{Y|H}(y|1)$ y $P_{Y|H}(y|0)$ por $\\frac{e^{-\\lambda_1}*\\lambda_1^{x}}{x!}$ y $\\frac{e^{-\\lambda_0}*\\lambda_0^{x}}{x!}$ respectivamente, y $P_H(0)$ y $P_H(1)$ por 0.7 y 0.3 respectivamente\n",
    "\n",
    "    $\\frac{e^{-\\lambda_1}*\\lambda_1^{x}}{x!}*0.3   \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}}  \\frac{e^{-\\lambda_0}*\\lambda_0^{x}}{x!}*0.7$  Se cancelan los factoriales\n",
    "\n",
    "    $e^{-\\lambda_1}*\\lambda_1^{x}*0.3  \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}}  e^{-\\lambda_0}*\\lambda_0^{x}*0.7$    Ahora se despejan los numeros, de las variables\n",
    "\n",
    "    $\\frac{\\lambda_1^{x}}{\\lambda_0^{x}}  \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}} \\frac{e^{\\lambda_1}}{e^{\\lambda_0}} * \\frac{0.7}{0.3}$ Luego reemplazo cada $\\lambda$ por su valor correspondiente\n",
    "\n",
    "    $\\frac{3^{x}}{1^{x}}  \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}} e^{2} * \\frac{7}{3}$     Ahora, ya que $1^{x}$ es constante, lo elimino y aplico logaritmos de base 3 a ambos miembros\n",
    "\n",
    "    $x = log_3{3^{x}} \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}}    log_3{e^{2}* \\frac{7}{3}} = 2.59$ ----->            Entonces, $x \\frac{\\overset{\\hat{H} = 1}{\\geqslant}}{\\underset{\\hat{H} = 0}{<}} 2.591722$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simulación Montecarlo para el nivel de decisión 2.5917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Probabilidad de Error es: 0.18564999999999998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "intentos = 100000\n",
    "decision = 2.5917\n",
    "\n",
    "def pdf(i):\n",
    "    if(i == 1):\n",
    "        return np.random.poisson(1)\n",
    "    else:\n",
    "        return np.random.poisson(3)\n",
    "\n",
    "\n",
    "Z = np.random.randint(1,101,intentos)\n",
    "H = [1 if Z[n]>=70 else 0 for n in range(len(Z))]\n",
    "\n",
    "Y = [pdf(1) if H[n]==0 else pdf(3) for n in range(len(H))]\n",
    "\n",
    "Y_Decodificada = [1 if Y[n] >= decision else 0 for n in range(len(Y))]\n",
    "\n",
    "correctos = 0\n",
    "for n in range(len(Y_Decodificada)):\n",
    "    if(H[n] == Y_Decodificada[n]):\n",
    "        correctos += 1\n",
    "\n",
    "Pe = 1 - correctos/intentos\n",
    "\n",
    "print(\"La Probabilidad de Error es:\",Pe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cambiando el nivel de decisión por 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Probabilidad de Error es: 0.24334\n"
     ]
    }
   ],
   "source": [
    "intentos = 100000\n",
    "decision = 1.8\n",
    "\n",
    "def pdf(i):\n",
    "    if(i == 1):\n",
    "        return np.random.poisson(1)\n",
    "    else:\n",
    "        return np.random.poisson(3)\n",
    "\n",
    "\n",
    "Z = np.random.randint(0,101,intentos)\n",
    "H = [1 if Z[n]>=70 else 0 for n in range(len(Z))]\n",
    "\n",
    "Y = [pdf(1) if H[n]==0 else pdf(3) for n in range(len(H))]\n",
    "\n",
    "Y_Decodificada = [1 if Y[n] >= decision else 0 for n in range(len(Y))]\n",
    "\n",
    "correctos = 0\n",
    "for n in range(len(Y_Decodificada)):\n",
    "    if(H[n] == Y_Decodificada[n]):\n",
    "        correctos += 1\n",
    "\n",
    "Pe = 1 - correctos/intentos\n",
    "\n",
    "print(\"La Probabilidad de Error es:\",Pe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
